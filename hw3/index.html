<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Names: Kunhong Lyu, Isabella Hu </div>

		<br>

		Link to webpage: <a href="https://lapluma430.github.io/cs184hw_website/">Isabella Hu and Kunhong Lyu's HW website</a>

		<br>
		
		Link to GitHub repository: <a href="https://github.com/cal-cs184/hw-pathtracer-updated-very-cooked.git">github.com/cal-cs184/hw-pathtracer-updated-very-cooked.git</a>

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		<p>
			In this assignment, we implemented a physically-based renderer using path tracing to simulate realistic light interactions in 3D scenes. The system works by:
		</p>
		<ul>
			<li>Generating camera rays and computing object intersections (accelerated by BVH spatial partitioning)</li>
			<li>Estimating direct lighting through uniform and importance sampling</li>
			<li>Simulating global illumination effects (soft shadows, color bleeding, reflections) using path tracing with Russian Roulette termination</li>
			<li>Optimizing rendering through adaptive sampling to reduce noise</li>
		</ul>
		<p>
			This rendering technique is fundamental to film and game production pipelines. One particularly interesting 
			insight was seeing how mathematical formulas combine together to produce realistic images.
		</p>
		<h2>Part 1: Ray Generation and Scene Intersection</h2>

		<h3>Ray Generation</h3>
		<p>
			The ray generation is implemented in <code>generate_ray</code>, which sents an initial ray from the sampling point 
			on the camera plane to its corresponding position at the image(sensor) plane. 
		<ol>
			<li><strong>FOV Conversion</strong>:
				<ul>
					<li>Calculate sensor plane dimensions using the hFov and 
						vFov and using a pinhole camera model with the sensor plane placed 1 
						unit away from the camera origin: </li>
					<li><code>sensorWidth = 2 * tan(hFov/2)</code></li>
					<li><code>sensorHeight = 2 * tan(vFov/2)</code></li>
				</ul>
				( tan(vFov/2) = opposite/adjacent, since adjacent is the distance to the sensor plane = 1,  we can find the length of the opposite edge which is the sensor dimensions)
			</li>
			<li><strong>Coordinate Mapping</strong>: Transform pixel coordinates (x,y) to sensor plane positions</li>
			<li><strong>Ray Creation</strong>: Convert position to world space coordinate using <code>c2w</code> matrix and generate ray through that point</li>
		</ol>

		<p>
			In <code>raytrace_pixel</code>, we:
		</p>
		<ul>
			<li>Generate <code>ns_aa</code> rays per pixel by calling camera-> generate_ray for each normalized sample point to sent initial ray</li>
			<li>Call <code>est_radiance_global_illumination()</code> for each ray to calculate the light contribution</li>
			<li>Average results for final pixel color and  set it to sampleBuffer.</li>
		</ul>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="banana.png" width="250px"/>
				  <figcaption>banana.dae after task 2</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="CBempty.png" width="250px"/>
				  <figcaption>CBempty.dae after task 2</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<h3>Triangle Intersection</h3>
		<p>
			Both the <code>has_intersection</code> and <code> intersect</code> function are implemented using the Möller-Trumbore algorithm (to find Barycentric coordinate):
		</p>
		<pre>
		Ray equation: O + tD = (1-u-v)P0 + uP1 + vP2
		Solved using:
		t = (Q • E2) / (D • E1)
		u = (P • T) / (D • E1)
		v = (Q • D) / (D • E1)
		Where:
		E1 = P1-P0, E2 = P2-P0
		T = O - P0
		P = D × E2
		Q = T × E1
		</pre>
		<p>check if all the coefficient <code>u, v, (1-u-v)</code> are between 0-1, if so, the point is within the triangle</p>
		<p>
			Key differences between functions:
		</p>
		<ul>
			<li><code>has_intersection</code>: Returns true/false for hit detection</li>
			<li><code>intersect</code>: Updates <code>Intersection</code> struct with hit details (time, normal, material, primitive)</li>
		</ul>
		<p>Some images with normal shading for small .dae files:</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="CBcoil.png" width="250px"/>
				  <figcaption>CBcoil.dae (1032KB)</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="CBspheres.png" width="250px"/>
				  <figcaption>CBspheres.dae (27KB)</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="CBemptyw.png" width="250px"/>
				  <figcaption>CBempty.dae (23KB)</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<br>

		
		<h2>Bounding Volume Hierarchy</h2>
		<p>
			I implemented the BVH recursively by partitioning the primitive top down into a binary tree:
		</p>
		<ol>
			<li><strong>Compute Bounding Box</strong>:
				<ul>
					<li>For each node, create a bounding box (bbox)</li>
					<li>Expand it to enclose all primitives in range [start, end)</li>
				</ul>
			</li>
			
			<li><strong>Leaf Node Check</strong>:
				<ul>
					<li>If number of primitives ≤ max_leaf_size (we reach the max size), then we 
					store all primitives in node (no further splitting)</li>
				</ul>
			</li>
			
			<li><strong>Splitting Heuristic</strong>:
				<ul>
					<li>Split on longest axis at midpoint</li>
					<li>To find the longest axis of the boundng box, we calculate diagonal vector using 
						bbox.max - bbox.min, and find axis with largest span (x/y/z)</li>
					<li>Calculate midpoint index</li>
					<li>Use nth_element to partition primitives based on centroid position with midpoint in the correct position</li>
					<li>Construct new bvh using the construct_bvh and on each of the partitions</li>
				</ul>
			</li>
		</ol>

		<h3>Intersection Functions</h3>
		<p>For the BVHAccel class, we also have the has_intersection (for early termination) and intersect (closest hit) method:</p>

		<p>We implemnted both use recursive approach:</p>
		<ol>
			<li>If ray doesn't intersect node's bbox → return false (ray going through the empty space)</li>
			<li>If ray intersects bbox:
				<ul>
					<li><strong>Leaf node</strong>:
						<ul>
							<li>Iterate through all primitives</li>
							<li>Check intersection using primitive's methods</li>
							<li>For <em>intersect()</em> function specifically:
								<ul>
									<li>If local_isect occurs before current intersection</li>
									<li>Update current intersection (i) to local_isect</li>
									<!--  We still need to check other primitives because:
										1. Transparent objects would need secondary intersections
										2. Earlier hits might have higher transparency -->
								</ul>
							</li>
						</ul>
					</li>
					<li><strong>Non-leaf node</strong>:
						<ul>
							<li>Recursively check left and right children</li>
						</ul>
					</li>
				</ul>
			</li>
		</ol>

		<h3>BBox Intersection</h3>
		<p>This function is for when checking of ray intersect with the bbox, implementation uses lecture's box intersection method:</p>
		<ul>
			<li>For each axis (x/y/z):
				<ul>
					<li>Calculate t_enter and t_exit using:
						<pre>t_enter = (min[axis] - ray.o[axis]) / ray.d[axis]</pre>
							<pre>t_exit = (max[axis] - ray.o[axis]) / ray.d[axis]</pre>
					</li>
					<li>Swap if t_enter > t_exit</li>
				</ul>
			</li>
			<li>Final t_enter = max(t_enter_x, t_enter_y, t_enter_z)</li>
			<li>Final t_exit = min(t_exit_x, t_exit_y, t_exit_z)</li>
			<li>Intersection occurs if:
				<ul>
					<li>t_enter ≤ t_exit (ray spends time inside box)</li>
					<li>t_exit ≥ ray.min_t AND t_enter ≤ ray.max_t</li>
					<!-- AI Note: No intersection when t_enter > t_exit because:
						- Means ray misses box in at least one axis
						- Example: t_enter_x > t_exit_y → ray passes outside box in y-axis before entering x-axis -->
				</ul>
			</li>
			<li>Update t0/t1 to [t_enter, t_exit] if intersection found</li>
		</ul>
		<p>Some images with normal shading using BVH acceleration for large .dae files: </p>
			<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="CBdragon_int.png" width="250px"/>
				</td>
				<td style="text-align: center;">
				  <img src="CBlucyIntersection.png" width="250px"/>
				</td>
			</tr>
			 <tr>
				<td style="text-align: center;">
				  <img src="cow.png" width="250px"/>
				</td>
				<td style="text-align: center;">
				  <img src="maxplanck.png" width="250px"/>
				</td>
			  </tr>
			</table>
		</div>
		<p>The BVH acceleration resulted in dramatic performance improvements across all test files, with
			 a speedup of approximately 80 times compared to brute-force intersection testing, depending on
			  the complexity of the scene. The cow.dae scene saw an improvement from 91.43 seconds to 1.15 
			  seconds (79 times faster), while beetle.dae showed the most significant gain—from 116.73 seconds to 1.12 seconds (106 times faster). The teapot.dae scene was approximately 40 times faster with BVH.
These results shows that BVH performs especially well in scenes with high complexity, where the
 optimization becomes more noticeable due to the partitioning structure effectively skipping many primitive
  intersection tests. Overall, the results show that BVH is highly effective in optimizing the runtime of the renderer.
</p>

		<h2>Part 3: Direct Illumination</h2>

		<h3>Hemisphere Sampling (<code>estimate_direct_lighting_hemisphere</code>)</h3>
		<p>Determine the color coming from any light source at the intersection point using uniform sampling in a hemisphere.</p>
		<ol>
		<li>Creates a local coordinate system aligned with the surface normal (<code>o2w</code> matrix)</li>
		<li>Generates uniform samples over a hemisphere centered at the hit point</li>
		<li>For each sample:
			<ul>
			<li>Converts from hemisphere coordinates to world coordinates: <code>wi_world = o2w * w_in</code></li>
			<li>Casts a shadow ray toward the sampled direction: <code>Ray shadow_ray(hit_p, wi_world)</code></li>
			<li>Uses <code>bvh->intersect</code> to update the closest intersection and check for hits</li>
			<li>If intersection exists and is a light source (<code>emission > 0</code>):
				<ul>
				<li>Calculates incoming radiance (<code>L_i</code>) from light emission</li>
				<li>Evaluates BRDF (<code>f</code>) at intersection point (how surface reflects light)</li>
				<li>Computes cosine term (<code>abs_cos_theta</code>) (light reception efficiency based on angle)</li>
				</ul>
			</li>
			</ul>
		</li>
		<li>Averages results and divides by uniform PDF (<code>1/(2π)</code>)</li>
		</ol>

		<h3>Importance Sampling (<code>estimate_direct_lighting_importance</code>)</h3>
		<p>Samples only from light directions instead of uniform hemisphere sampling, producing less noisy and more efficient results.</p>
		<ol>
		<li>Iterates through all lights in scene:
			<ul>
			<li><strong>For non-delta lights (area lights):</strong>
				<ul>
				<li>Takes <code>ns_area_light</code> samples per light</li>
				<li>Uses <code>light->sample_L()</code> to get: Light direction (<code>wi</code>), Distance to light, PDF of sample</li>
					
				<li>Checks visibility with shadow ray (only if ray is in desired hemisphere)</li>
				<li>Constructs shadow ray with:
					<ul>
					<li>Origin (<code>hit_p + wi * 1e-4</code>)</li>
					<li>Direction (<code>wi</code>)</li>
					<li><code>min_t = 1e-4</code> (avoid self-intersection)</li>
					<li><code>max_t = distToLight - 1e-4</code> (stop at light source)</li>
					</ul>
				</li>
				<li>If no intersection before <code>max_t</code> (the ray is able to reaches light and the point is not in shadow):
					<ul>
					<li>Computes BRDF at first intersection</li>
					<li>Calculates total light contribution: <code>L_i * f * cosine_term</code></li>
					</ul>
				</li>
				</ul>
			</li>
			<li><strong>For delta lights (point lights):</strong>
				<ul>
				<li>Takes single sample (exact calculation)</li>
				<li>Same visibility/BRDF calculation as area lights</li>
				<li>Properly weights by light sample PDF</li>
				</ul>
			</li>
			</ul>
		</li>
		</ol>
			<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="part3/bunny_I_16_8.png" width="300px"/>
				  <figcaption>importance sampling -s=16, -l=8</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part3/bunny_16_8_hem.png" width="300px"/>
				  <figcaption>hemisphere sampling -s=16, -l=8</figcaption>
				</td>
				</tr>
				<tr>
				<td style="text-align: center;">
				  <img src="part3/bunny_64_32.png" width="300px"/>
				  <figcaption>importance sampling -s=64, -l=32</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part3/CBbunny_H_64_32.png" width="300px"/>
				  <figcaption>hemisphere stampling -s=64, -l=32</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<figure>
			<img src="part3/dragon_64_32.png" alt="Cornell Boxes with Bunnies" style="width:70%"/>
			<figcaption>dragon.dae with importance sampling</figcaption>
		</figure>

				<p>Same scene importance sampling at diffent numbers of light ray</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
				<td style="text-align: center;">
				  <img src="part3/bunny_1_1.png" width="300px"/>
				  <figcaption>CBbunny.dae with -l=1</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part3/bunny_1_4_t4.png" width="300px"/>
				  <figcaption>CBbunny.dae with -l=4</figcaption>
				</td>
			  <tr>
				<td style="text-align: center;">
				  <img src="part3/bunny_1_16_t4.png" width="300px"/>
				  <figcaption>CBbunny.dae with -l=16</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part3/bunny_1_64_t4.png" width="300px"/>
				  <figcaption>CBbunny.dae with -l=64</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p>The importance sampling version produces significantly less noise when using the same number 
			of samples. Hemisphere sampling tends to produce noisier images since many of the samples miss
			 the light entirely, while importance sampling ensures every sample makes a meaningful 
			 contribution to the final result (L_out). In the CBbunny example, while the noise for 
			 hemisphere sampling is uniformly distributed, the noise for importance sampling is mostly 
			 concentrated in the shadow areas. This occurs because importance sampling focuses samples 
			 on light sources, making well-lit regions converge faster while shadow regions remain noisier.
			  Hence, importance sampling is generally better and 
			 more efficient for direct lighting calculations.</p>
		<br>

		
		<h2>Part 4: Global Illumination</h2>
			<h3>BSDF Sampling</h3>
			<p>
				The <code>bsdf->get_sample()</code> function:
			</p>
			<ul>
				<li>Randomly picks a "likely" light direction based on the density function</li>
				<li>Computes its PDF (probability density function)</li>
				<li>For diffuse objects, <code>f(wi, wo)</code> always returns a constant: <code>albedo/π</code></li>
				<li>This is because diffuse objects reflect the same amount of light regardless of angles</li>
			</ul>

			<h3>Global Illumination Implementation</h3>
			<p>
				Global illumination simulates how light bounces multiple times between surfaces to produce realistic indirect lighting. 
				Implementation is similar to one-bounce but with recursion:
			</p>
			<ol>
				<li>
				<strong>Initial setup</strong> (<code>hit_p</code>, <code>w_out</code> etc.) is the same.
				However we do set <code>L_out</code> to <code>one_bounce_radiance</code> (direct lighting contribution) at current intersection
				</li>
				<li>
				Track ray depth using <code>r.depth</code> variable and terminate recursion if ray exceeds <code>max_ray_depth</code>
				</li>
				<li>
				Otherwise, call <code>isect.bsdf->sample_f()</code> to get possible light direction from diffuse BSDF
				</li>
				<li>
				Generate a ray <code>next_ray</code> from current intersection with the sampled direction,
				and increment ray depth by 1
				</li>
			</ol>

			<h4>Russian Roulette Termination</h4>
			<p>
				Added because <code>max_ray_depth</code> alone doesn't yield realistic models:
			</p>
			<ul>
				<li>The rule is: always trace at least one indirect bounce when enabled</li>
				<li>Then use 30% termination probability for subsequent bounces</li>
				<li>Enter recursion only if either:
				<ul>
					<li>This is the first bounce, OR We hit the 70% probability to continue</li>
				</ul>
				</li>
			</ul>

			<h4>Recursive Call</h4>
			<p>
				Call <code>at_least_one_bounce_radiance</code> to:
			</p>
			<ul>
				<li>Find light contribution from <code>next_ray</code></li>
				<li>Weight the contribution appropriately</li>
			</ul>

			<h4>Result Accumulation</h4>
			<p>
				Two modes:
			</p>
			<ul>
				<li>If <code>isAccumBounces</code> is true: accumulate all bounces</li>
				<li>Otherwise: isolate specific bounce level (mostly for debugging)</li>
			</ul>
			<div style="display: flex; flex-direction: column; align-items: center;">

			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
				<td style="text-align: center;">
				  <img src="part5/CBspheres_lambertian_indirect.png" width="300px"/>
				  <figcaption>indirect -s=2048</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/CBsphere_lamb_t4_direct.png" width="300px"/>
				  <figcaption>direct  -s=2048</figcaption>
				</td>
			</table>
			</div>
			<br>
			<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<p>isAccumBounces = false: </p>
				<tr>
				<td style="text-align: center;">
				  <img src="part5/m0.png" width="110px"/>
				  <figcaption>m = 0 </figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/m1.png" width="110px"/>
				  <figcaption>m = 1</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/m2.png" width="110px"/>
				  <figcaption>m = 2</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/m3.png" width="110px"/>
				  <figcaption>m = 3</figcaption>
				</td><td style="text-align: center;">
				  <img src="part5/m4.png" width="110px"/>
				  <figcaption>m = 4</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/m5.png" width="110px"/>
				  <figcaption>m = 5</figcaption>
				</td>
			</table>
			</div>	<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<p>isAccumBounces = true: </p>
				<tr>
				<td style="text-align: center;">
				  <img src="part5/m0t.png" width="110px"/>
				  <figcaption>m = 0 </figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/m1t.png" width="110px"/>
				  <figcaption>m = 1</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/m2t.png" width="110px"/>
				  <figcaption>m = 2</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/m3t.png" width="110px"/>
				  <figcaption>m = 3</figcaption>
				</td><td style="text-align: center;">
				  <img src="part5/m4t.png" width="110px"/>
				  <figcaption>m = 4</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/m5t.png" width="110px"/>
				  <figcaption>m = 5</figcaption>
				</td>
			</table>
			</div>
			<p>When isAccumBounces is enabled, the rendered photo accumulates light
				 contributions from all previous bounces, which brightening 
				 the scene (especially in shadowed), which results in a more physically accurate, 
				 globally illuminated image. As max_ray_depth increases, each additional 
				 bounce refines indirect lighting: lower depths (1–2) captures soft shadows and color bleeding, 
				 while higher depths (3–5) subtly brighten the object. Without accumulation (isAccumBounces=false), 
				 each bounce is isolated, revealing how indirect light are adding up.</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<p>With Russian Roulette: </p>
				<tr>
				<td style="text-align: center;">
				  <img src="part5/m0r.png" width="110px"/>
				  <figcaption>m = 0 </figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/m1r.png" width="110px"/>
				  <figcaption>m = 1</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/m2r.png" width="110px"/>
				  <figcaption>m = 2</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/m3r.png" width="110px"/>
				  <figcaption>m = 3</figcaption>
				</td><td style="text-align: center;">
				  <img src="part5/m4r.png" width="110px"/>
				  <figcaption>m = 4</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/m5r.png" width="110px"/>
				  <figcaption>m = 5</figcaption>
				</td>
			</table>
			</div>
			<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<p>Increase s: </p>
				<tr>
				<td style="text-align: center;">
				  <img src="part5/s1.png" width="110px"/>
				  <figcaption>s = 1 </figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/s2.png" width="110px"/>
				  <figcaption>s = 2</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/s3.png" width="110px"/>
				  <figcaption>s = 4</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/s4.png" width="110px"/>
				  <figcaption>s = 8</figcaption>
				</td><td style="text-align: center;">
				  <img src="part5/s5.png" width="110px"/>
				  <figcaption>s = 16</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/s6.png" width="110px"/>
				  <figcaption>s = 64</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="part5/s7.png" width="110px"/>
				  <figcaption>s = 1024</figcaption>
				</td>
			</table>
			</div>

		
			

		<h2>Part 5: Adaptive Sampling</h2>
				<p>Traditional fixed-rate sampling applies the same number of samples to every pixel, which is inefficient because:</p>
				<ul>
				<li><strong>Simple Areas</strong>: Pixels in uniform regions (like flat walls) converge quickly with few samples</li>
				<li><strong>Complex Areas</strong>: Pixels in regions with complex lighting (shadows, reflections) require many more samples to reduce noise</li>
				</ul>
				<p>Adaptive sampling solves this inefficiency by dynamically adjusting sample counts per pixel using statistical analysis.</p>
				<h3>Convergence Monitoring</h3>
				<ul>
				<li><code>s₁</code>: Cumulative sum of all sample illuminance values</li>
				<li><code>s₂</code>: Cumulative sum of squared illuminance values</li>
				<li>These running totals enable efficient variance calculation without storing individual samples</li>
				<li>Uses the Central Limit Theorem with a 95% confidence interval to estimate stability</li>
				</ul>
			

				<h3>Batch Processing Workflow</h3>
				<h4>Per-Pixel Sampling</h4>
				<ul>
					<li>Take samples up to maximum limit</li>
					<li>Check convergence only every <code>samplesPerBatch</code> and early termination when convergence detected</li>
				</ul>
				
				<h4>Convergence Check</h4>
				<ul>
					<li>Compute statistics every batch:
					<ul>
						<li>Mean illuminance: μ = s₁/n</li>
						<li>Variance: σ² = (s₂ - (s₁²/n))/(n-1)</li>
					</ul>
					</li>
					<li>Stop when confidence interval (CI = 1.96√(σ²/n)) &lt; 5% of mean</li>
				</ul>

				<h4>Tracking Adjustments</h4>
				<ul>
					<li>Record actual samples used (<var>s</var>) in <code>sampleCountBuffer</code></li>
					<li>Final pixel color = ∑(sample_colors)/<var>s</var></li>
				</ul>
	
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
					<td style="text-align: center;">
					<img src="part5/bunny_t51.png" width="300px"/>
					<figcaption>bunny.png -s=2048</figcaption>
					</td>
					<td style="text-align: center;">
					<img src="part5/bunny_t52.png" width="300px"/>
					<figcaption>bunny_rate -s=2048</figcaption>
					</td>
				<tr>
					<td style="text-align: center;">
					<img src="part5/CBsphere_lamb_t4_1.png" width="300px"/>
					<figcaption>CBsphere -s=2048</figcaption>
					</td>
					<td style="text-align: center;">
					<img src="part5/CBsphere_lamb_t4_rate1.png" width="300px"/>
					<figcaption>CBsphere_rate -s=2048</figcaption>
					</td>
				</tr>
				</table>
			</div>
				</div>
			<!-- <h2>(Optional) Part 6: Extra Credit Opportunities</h2>
			Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat 
			non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.-->
		</div> 
		<h3>AI Usage:</h3>
		<p>I used AI to translate my write-up into HTML and assist with debugging tasks</p>
		</div>
	</body>
</html>